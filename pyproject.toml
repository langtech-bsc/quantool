[build-system]
requires = ["hatchling>=1.21"]
build-backend = "hatchling.build"

[tool.hatch.metadata]
# Needed so PEP 508 direct references (git/file URLs) are allowed in dependencies
allow-direct-references = true

[project]
name="quantool"
version = "0.0.1"                             # Alpha release
description = "A unified, plugin-based quantization toolkit for LLMs"
readme = "README.md"                          # Path to long-form project description
requires-python = ">=3.8,<3.12"              # Minimum Python support
authors = [
    { name="Quantool Team", email="igor.kuzmin@bsc.es" }
]
#license = { file="LICENSE" }                 # Path to license file
keywords = [
    "quantization",
    "llm",
    "plugin",
    "toolkit",
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11"
]
dependencies = [
    "torch>=2.0.0",
    "transformers>=4.0.0",
    "accelerate>=0.16.0",
    "datasets>=2.0.0",
    "peft>=0.3.0",
    "onnxruntime>=1.15.0",
    "onnx>=1.15.0",
    "scikit-learn>=1.0",
    "scipy>=1.7",
    "numpy>=1.21",
    "pandas>=1.3",
    "loguru"
]

[project.optional-dependencies]
dev = [
    "pytest>=6.0",
    "black>=22.0",
    "isort>=5.0",
]

aqlm = [
    "aqlm_scripts @ git+https://github.com/langtech-bsc/AQLM.git@main#egg=aqlm_scripts"
]

llama-cpp = [
  "llama-cpp-scripts @ git+https://github.com/ggml-org/llama.cpp.git@master#egg=llama-cpp-scripts"
]
awq = ["llmcompressor"]
#higgs = ["flute-kernel"]

wandb = ["wandb>=0.16.3", "pandas", "numpy"]
mlflow = ["mlflow"]
all = [
    "quantool[aqlm]",
#    "quantool[qptq]",
    "quantool[llama-cpp]",
#    "quantool[awq]",
#    "quantool[higgs]",
]


[project.scripts]
quantool="quantool.entrypoints.cli:main"

[tool.hatch.build.targets.wheel]
packages = ["src/quantool"]